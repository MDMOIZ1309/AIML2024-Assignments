{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7X4R6x8kwFI",
        "outputId": "3d1ac700-a574-4d3d-8c81-48c26a6a5e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Age     Na_to_K\n",
            "count  200.000000  200.000000\n",
            "mean    44.315000   16.084485\n",
            "std     16.544315    7.223956\n",
            "min     15.000000    6.269000\n",
            "25%     31.000000   10.445500\n",
            "50%     45.000000   13.936500\n",
            "75%     58.000000   19.380000\n",
            "max     74.000000   38.247000\n",
            "NULL VALUES\n",
            "       Age    Sex     BP  Cholesterol  Na_to_K   Drug\n",
            "0    False  False  False        False    False  False\n",
            "1    False  False  False        False    False  False\n",
            "2    False  False  False        False    False  False\n",
            "3    False  False  False        False    False  False\n",
            "4    False  False  False        False    False  False\n",
            "..     ...    ...    ...          ...      ...    ...\n",
            "195  False  False  False        False    False  False\n",
            "196  False  False  False        False    False  False\n",
            "197  False  False  False        False    False  False\n",
            "198  False  False  False        False    False  False\n",
            "199  False  False  False        False    False  False\n",
            "\n",
            "[200 rows x 6 columns]\n",
            "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
            "0     23   F    HIGH        HIGH   25.355  drugY\n",
            "1     47   M     LOW        HIGH   13.093  drugC\n",
            "2     47   M     LOW        HIGH   10.114  drugC\n",
            "3     28   F  NORMAL        HIGH    7.798  drugX\n",
            "4     61   F     LOW        HIGH   18.043  drugY\n",
            "..   ...  ..     ...         ...      ...    ...\n",
            "195   56   F     LOW        HIGH   11.567  drugC\n",
            "196   16   M     LOW        HIGH   12.006  drugC\n",
            "197   52   M  NORMAL        HIGH    9.894  drugX\n",
            "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
            "199   40   F     LOW      NORMAL   11.349  drugX\n",
            "\n",
            "[200 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "a = pd.read_csv(\"/content/drug200AIML.csv\")\n",
        "print(a.describe())\n",
        "a\n",
        "#Null values\n",
        "print('NULL VALUES')\n",
        "nullvalues=a.isnull()\n",
        "print(nullvalues)\n",
        "a_mean=a.fillna(0)\n",
        "print(a_mean)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drug200AIML.csv\")\n",
        "\n",
        "# Convert categorical variables into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['BP'] = label_encoder.fit_transform(data['BP'])\n",
        "data['Cholesterol'] = label_encoder.fit_transform(data['Cholesterol'])\n",
        "data['Drug'] = label_encoder.fit_transform(data['Drug'])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = data.drop('Drug', axis=1)\n",
        "y = data['Drug']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the KNN classifier\n",
        "k = 5  # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print('K- NEAREST NEIGHBOUR MODEL')\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "k3chPQjsyw0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355026d2-c0ab-44da-d745-ffc54bc674d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K- NEAREST NEIGHBOUR MODEL\n",
            "Accuracy: 0.7\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.50      0.55         6\n",
            "           1       0.33      0.67      0.44         3\n",
            "           2       1.00      0.20      0.33         5\n",
            "           3       0.54      0.64      0.58        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.69      0.60      0.58        40\n",
            "weighted avg       0.76      0.70      0.69        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "# Train the SVM classifier\n",
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "print('SUPPORT VECTOR MACHINE MODEL')\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "\n",
        "#Decision Tree\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drug200AIML.csv\")\n",
        "\n",
        "# Convert categorical variables into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['BP'] = label_encoder.fit_transform(data['BP'])\n",
        "data['Cholesterol'] = label_encoder.fit_transform(data['Cholesterol'])\n",
        "data['Drug'] = label_encoder.fit_transform(data['Drug'])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = data.drop('Drug', axis=1)\n",
        "y = data['Drug']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print('DECISION-TREE MODEL')\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "RYE3X9UIy5pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8513ddd9-e6ca-4900-bf2e-a583bf84258b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUPPORT VECTOR MACHINE MODEL\n",
            "SVM Accuracy: 0.625\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         6\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.43      0.91      0.59        11\n",
            "           4       0.88      1.00      0.94        15\n",
            "\n",
            "    accuracy                           0.62        40\n",
            "   macro avg       0.26      0.38      0.31        40\n",
            "weighted avg       0.45      0.62      0.51        40\n",
            "\n",
            "DECISION-TREE MODEL\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the logistic regression classifier\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print('LOGISTIC REGRESSION MODEL')\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))"
      ],
      "metadata": {
        "id": "AQnjZ3BPzFz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d109768-03f1-4ea0-e5ff-4919eccd82b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOGISTIC REGRESSION MODEL\n",
            "Accuracy: 0.9\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       0.75      1.00      0.86         3\n",
            "           2       1.00      0.40      0.57         5\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           0.90        40\n",
            "   macro avg       0.90      0.86      0.85        40\n",
            "weighted avg       0.92      0.90      0.89        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drug200AIML.csv\")\n",
        "\n",
        "# Convert categorical variables into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['BP'] = label_encoder.fit_transform(data['BP'])\n",
        "data['Cholesterol'] = label_encoder.fit_transform(data['Cholesterol'])\n",
        "data['Drug'] = label_encoder.fit_transform(data['Drug'])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = data.drop('Drug', axis=1)\n",
        "y = data['Drug']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust the number of trees as needed\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print('RANDOM FOREST MODEL')\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "8isERDlIzlf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eeeb69d-8aa4-414d-8aab-3e08420beb82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANDOM FOREST MODEL\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADABOOST\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drug200AIML.csv\")\n",
        "\n",
        "# Convert categorical variables into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['BP'] = label_encoder.fit_transform(data['BP'])\n",
        "data['Cholesterol'] = label_encoder.fit_transform(data['Cholesterol'])\n",
        "data['Drug'] = label_encoder.fit_transform(data['Drug'])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = data.drop('Drug', axis=1)\n",
        "y = data['Drug']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the base estimator (weak learner)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Train the AdaBoost classifier\n",
        "clf = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print('ADABOOST MODEL')\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "oQZraObLz0FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e87999-2a0b-4136-b5be-6abb4f6f8ade"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADABOOST MODEL\n",
            "Accuracy: 0.8\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         6\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           0.80        40\n",
            "   macro avg       0.47      0.60      0.52        40\n",
            "weighted avg       0.66      0.80      0.72        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}